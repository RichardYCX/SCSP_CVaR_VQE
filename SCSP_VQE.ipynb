{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de15eff8-cccd-4949-9bb4-c70b8a882850",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing standard Qiskit libraries\n",
    "from qiskit import QuantumCircuit, transpile\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from ibm_quantum_widgets import *\n",
    "\n",
    "# qiskit-ibmq-provider has been deprecated.\n",
    "# Please see the Migration Guides in https://ibm.biz/provider_migration_guide for more detail.\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService, Sampler, Estimator, Session, Options\n",
    "\n",
    "from docplex.mp.model import Model\n",
    "from qiskit.circuit.library import RealAmplitudes\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit.algorithms.minimum_eigensolvers import NumPyMinimumEigensolver, QAOA, SamplingVQE\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "# from qiskit.primitives import Sampler\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "from qiskit_optimization.translators import from_docplex_mp\n",
    "from qiskit_optimization.converters import InequalityToEquality, IntegerToBinary, LinearEqualityToPenalty, QuadraticProgramToQubo\n",
    "from qiskit.result import QuasiDistribution\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Loading your IBM Quantum account(s)\n",
    "service = QiskitRuntimeService(channel=\"ibm_quantum\")\n",
    "backend = service.get_backend('ibmq_qasm_simulator')\n",
    "sampler = Sampler(backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216ece82-ae0a-4652-b863-14f35830f351",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_random_instance(n: int, low: int = 0, high: int = 100, seed: int = None) -> \"Tsp\":\n",
    "    \"\"\"Create a random instance of the constraint satisfaction problem\n",
    "\n",
    "    Args:\n",
    "        n: the number of nodes.\n",
    "        low: The minimum value for the coordinate of a node.\n",
    "        high: The maximum value for the coordinate of a node.\n",
    "        seed: the seed for the random coordinates.\n",
    "\n",
    "    Returns:\n",
    "         A Csp instance created from the input information\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        algorithm_globals.random_seed = seed\n",
    "    coord = algorithm_globals.random.uniform(low, high, (n, 2))\n",
    "    pos = {i: (coord_[0], coord_[1]) for i, coord_ in enumerate(coord)}\n",
    "    graph = nx.random_geometric_graph(n, np.hypot(high - low, high - low) + 1, pos=pos)\n",
    "    for w, v in graph.edges:\n",
    "        delta = [graph.nodes[w][\"pos\"][i] - graph.nodes[v][\"pos\"][i] for i in range(2)]\n",
    "        graph.edges[w, v][\"weight\"] = np.rint(np.hypot(delta[0], delta[1]))\n",
    "        graph.edges[w, v][\"resource\"] = randint(20, 200)\n",
    "\n",
    "    return graph\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self, graph):\n",
    "        self._graph = graph\n",
    "        self._colors = [\"r\" for node in self._graph.nodes]\n",
    "        self._positions = [self._graph.nodes[node][\"pos\"] for node in self._graph.nodes]\n",
    "    \n",
    "    def draw_graph(self):\n",
    "        default_axes = plt.axes(frameon=True)\n",
    "        nx.draw_networkx(self._graph, node_color=self._colors, alpha=0.8, ax=default_axes, pos=self._positions)\n",
    "        edge_labels = {}\n",
    "        for u, v, data in self._graph.edges(data=True):\n",
    "            edge_labels[u, v] = f\"{data['weight']}\\n{data['resource']}\"\n",
    "        nx.draw_networkx_edge_labels(self._graph, pos=self._positions, edge_labels=edge_labels)\n",
    "    \n",
    "    def draw_result(self, result) -> None:\n",
    "        \"\"\"Draw the result with colors\n",
    "\n",
    "        Args:\n",
    "            result : The calculated result for the problem\n",
    "        \"\"\"\n",
    "        nx.draw(self._graph, with_labels=True, pos=self._positions)\n",
    "        nx.draw_networkx_edges(\n",
    "            self._graph,\n",
    "            self._positions,\n",
    "            edgelist=edgelist(result),\n",
    "            width=8,\n",
    "            alpha=0.5,\n",
    "            edge_color=\"tab:red\",\n",
    "        )\n",
    "        \n",
    "def sample_most_likely(state_vector):\n",
    "    from collections import OrderedDict\n",
    "    from qiskit.opflow import StateFn\n",
    "    \"\"\"Compute the most likely binary string from state vector.\n",
    "    Args:\n",
    "        state_vector (numpy.ndarray or dict): state vector or counts.\n",
    "    Returns:\n",
    "        numpy.ndarray: binary string as numpy.ndarray of ints.\n",
    "    \"\"\"\n",
    "    if isinstance(state_vector, QuasiDistribution):\n",
    "        values = list(state_vector.values())\n",
    "        n = int(np.log2(len(values)))\n",
    "        k = np.argmax(np.abs(values))\n",
    "        x = bitfield(k, n)\n",
    "        x.reverse()\n",
    "        x = np.asarray(x)\n",
    "        return x\n",
    "    elif isinstance(state_vector, (OrderedDict, dict)):\n",
    "        # get the binary string with the largest count\n",
    "        binary_string = sorted(state_vector.items(), key=lambda kv: kv[1])[-1][0]\n",
    "        x = np.asarray([int(y) for y in reversed(list(binary_string))])\n",
    "        return x\n",
    "    elif isinstance(state_vector, StateFn):\n",
    "        binary_string = list(state_vector.sample().keys())[0]\n",
    "        x = np.asarray([int(y) for y in reversed(list(binary_string))])\n",
    "        return x\n",
    "    else:\n",
    "        n = int(np.log2(state_vector.shape[0]))\n",
    "        k = np.argmax(np.abs(state_vector))\n",
    "        x = np.zeros(n)\n",
    "        for i in range(n):\n",
    "            x[i] = k % 2\n",
    "            k >>= 1\n",
    "        return x\n",
    "\n",
    "def interpret(result, n):\n",
    "    \"\"\"Interpret a result as a list of node indices\n",
    "\n",
    "    Args:\n",
    "        result : The calculated result of the problem\n",
    "\n",
    "    Returns:\n",
    "        A list of nodes whose indices correspond to its order in a prospective cycle.\n",
    "    \"\"\"\n",
    "    c = 0\n",
    "    res = []\n",
    "    for i in range(n):\n",
    "        has_edge = False\n",
    "        for j in range(i+1, n):\n",
    "            if result[c]==1:\n",
    "                res.append(j)\n",
    "                has_edge = True\n",
    "            c+=1\n",
    "        if not has_edge:\n",
    "            res.append(-1)\n",
    "    return res\n",
    "\n",
    "\n",
    "def edgelist(route: np.ndarray):\n",
    "    # Arrange route and return the list of the edges for the edge list of nx.draw_networkx_edges\n",
    "    return [(i, route[i]) for i in range(len(route)) if route[i] != -1]\n",
    "\n",
    "def bitfield(n: int, L: int) -> list[int]:\n",
    "    result = np.binary_repr(n, L)\n",
    "    return [int(digit) for digit in result]  # [2:] to chop off the \"0b\" part\n",
    "\n",
    "\n",
    "def resource_used(solution, g):\n",
    "    used = 0\n",
    "    for start, end in enumerate(solution):\n",
    "        if end != -1:\n",
    "            used += g._graph.edges[start, end][\"resource\"]\n",
    "    return used\n",
    "\n",
    "# callback to store intermediate results\n",
    "def callback(evaluation_count, optimizer_parameters, estimated_value, metadata, intermediate_data):\n",
    "    # we translate the objective from the internal Ising representation\n",
    "    # to the original optimization problem\n",
    "    intermediate_data += [np.real_if_close(-(estimated_value + offset)),]\n",
    "\n",
    "    \n",
    "algorithm_globals.random_seed = 10598\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1edf7-88e8-4cab-b97f-93db60ca0121",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the plot shows that the right answer does not have the highest probability. I'm not sure why \n",
    "from qiskit_optimization.algorithms import SolutionSample, OptimizationResultStatus\n",
    "from qiskit.visualization import plot_distribution\n",
    "\n",
    "\n",
    "def get_filtered_samples(\n",
    "    samples: \"list[SolutionSample]\",\n",
    "    n_var: int, \n",
    "    threshold: float = 0,\n",
    "    allowed_status: \"tuple[OptimizationResultStatus]\" = (OptimizationResultStatus.SUCCESS,),\n",
    "):\n",
    "    res = []\n",
    "    n_var = (n_var * (n_var - 1)) // 2\n",
    "    samples_for_plot = {\n",
    "        str(s.x[:n_var]): 0.0 for s in samples\n",
    "    }\n",
    "    for s in samples:\n",
    "        if s.status in allowed_status and str(s.x[:n_var]) in samples_for_plot:\n",
    "            if sum(s.x[:n_var]) == 0:\n",
    "                continue\n",
    "            samples_for_plot[str(s.x[:n_var])] += s.probability\n",
    "    \n",
    "    total_prob = sum(samples_for_plot.values())\n",
    "    samples_for_plot = {k: v/total_prob for k, v in samples_for_plot.items()}\n",
    "    samples_for_plot = {k: v for k, v in samples_for_plot.items() if v >= threshold}\n",
    "    return samples_for_plot\n",
    "\n",
    "def plot_samples(result, samples, n_var):\n",
    "    samples_for_plot = {\n",
    "        # \" \".join(f\"{result.variables[i].name}={int(v)}\" for i, v in enumerate(s.x)): s.probability\n",
    "        # for s in samples\n",
    "        str(s.x): s.probability \n",
    "    }\n",
    "    return samples_for_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ac727-1980-4c53-8ef9-061c28808358",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def valid_csp_instance(n_node):\n",
    "    is_valid = False\n",
    "    while not is_valid:\n",
    "        # Create an instance of a model and variables with DOcplex.\n",
    "        max_resource_constraint = 100\n",
    "\n",
    "        # initial graph\n",
    "        csp_instance = create_random_instance(n_node)\n",
    "        graph = Graph(csp_instance)\n",
    "\n",
    "        adj_matrix = nx.to_numpy_array(graph._graph)\n",
    "        # print(\"distance\\n\", adj_matrix)\n",
    "\n",
    "        mdl = Model(name=f'{n_node}_csp')\n",
    "        x = {(i,j): mdl.binary_var(name=f'({i}->{j})') for i, j in graph._graph.edges}\n",
    "\n",
    "        # Object function\n",
    "        objective_func = mdl.sum(\n",
    "                    graph._graph.edges[i, j][\"weight\"] * x[(i, j)] \n",
    "                    for i, j in graph._graph.edges\n",
    "                ) #TODO: expand this to account for uncertainty\n",
    "        loss_func = mdl.sum(\n",
    "                    graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "                    for i, j in graph._graph.edges\n",
    "                )\n",
    "        # csp_func = objective_func + alpha * (loss_func - max_resource_constraint)\n",
    "        csp_func = objective_func\n",
    "\n",
    "        mdl.minimize(csp_func)\n",
    "\n",
    "        # Constraints\n",
    "        for i in range(1, n_node-1):\n",
    "            # flow conservation\n",
    "            mdl.add_constraint(mdl.sum(x[(k,i)] for k in range(0, i) if i != k) - \\\n",
    "                                mdl.sum(x[(i,j)] for j in range(i, n_node) if i != j) == 0)\n",
    "\n",
    "        mdl.add_constraint(mdl.sum(x[(0,i)] for i in range(1, n_node)) == 1)\n",
    "        mdl.add_constraint(mdl.sum(x[(i, n_node-1)] for i in range(n_node-1)) == 1)\n",
    "\n",
    "        # constraint satisfaction \n",
    "        mdl.add_constraint(mdl.sum(\n",
    "                    graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "                    for i, j in graph._graph.edges\n",
    "                ) <= max_resource_constraint)\n",
    "\n",
    "        # Call the method to convert the model into Ising Hamiltonian.\n",
    "        qp = from_docplex_mp(mdl)\n",
    "        # convert qb to quantum computing friendly format\n",
    "        qubo = QuadraticProgramToQubo().convert(qp)\n",
    "\n",
    "        # print(qubo.prettyprint())\n",
    "        uncertain_qubitOp, offset = qubo.to_ising()\n",
    "\n",
    "        # Making the Hamiltonian in its full form and getting the lowest eigenvalue and eigenvector\n",
    "        exact_mes = NumPyMinimumEigensolver()\n",
    "        exact = MinimumEigenOptimizer(exact_mes)\n",
    "        classical_result = exact.solve(qubo)\n",
    "\n",
    "        classical_most_likely = list(classical_result.variables_dict.values())\n",
    "        classical_solution = interpret(classical_most_likely, n_node)\n",
    "        is_valid = n_node-1 in classical_solution\n",
    "    print(classical_result.prettyprint())\n",
    "    print(\"resource_used:\", resource_used(classical_solution, graph))\n",
    "    return qubo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd3ef7c-595e-4851-8786-27e97dfe0ed2",
   "metadata": {},
   "source": [
    "#### CVaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc97d8-534f-495f-988a-f7c956dba32b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "objective_values = np.zeros(2**num_node)\n",
    "for i in range(2**num_node):\n",
    "    x_bin = ('{0:0%sb}' % num_node).format(i)\n",
    "    x = [0 if x_ == '0' else 1 for x_ in reversed(x_bin)]\n",
    "    objective_values[i] = qp.objective.evaluate(x)\n",
    "ind = np.argsort(objective_values)\n",
    "\n",
    "# evaluate final optimal probability for each alpha\n",
    "probabilities = np.zeros(len(objective_values))\n",
    "for alpha in alphas:\n",
    "    if backend_name == 'qasm_simulator':\n",
    "        counts = results[alpha].min_eigen_solver_result.eigenstate\n",
    "        shots = sum(counts.values())\n",
    "        for key, val in counts.items():\n",
    "            i = int(key, 2)\n",
    "            probabilities[i] = val / shots\n",
    "    else:\n",
    "        probabilities = np.abs(results[alpha].min_eigen_solver_result.eigenstate)**2\n",
    "    print('optimal probabilitiy (alpha = %.2f):  %.4f' % (alpha, probabilities[ind][-1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8180a3-b180-4625-b82a-c6ba454d5e12",
   "metadata": {},
   "source": [
    "#### with uncertainty in distance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf36be7-2392-4720-9d93-e5ff8cb04fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_random_uncertain_instance(n: int, low: int = 0, high: int = 100, seed: int = None) -> \"Tsp\":\n",
    "    \"\"\"Create a random instance of the constraint satisfaction problem\n",
    "\n",
    "    Args:\n",
    "        n: the number of nodes.\n",
    "        low: The minimum value for the coordinate of a node.\n",
    "        high: The maximum value for the coordinate of a node.\n",
    "        seed: the seed for the random coordinates.\n",
    "\n",
    "    Returns:\n",
    "         A Csp instance created from the input information\n",
    "    \"\"\"\n",
    "    if seed:\n",
    "        algorithm_globals.random_seed = seed\n",
    "    coord = algorithm_globals.random.uniform(low, high, (n, 2))\n",
    "    pos = {i: (coord_[0], coord_[1]) for i, coord_ in enumerate(coord)}\n",
    "    graph = nx.random_geometric_graph(n, np.hypot(high - low, high - low) + 1, pos=pos)\n",
    "    for w, v in graph.edges:\n",
    "        delta = [graph.nodes[w][\"pos\"][i] - graph.nodes[v][\"pos\"][i] for i in range(2)]\n",
    "        graph.edges[w, v][\"weight\"] = np.rint(np.hypot(delta[0], delta[1]))\n",
    "        graph.edges[w, v][\"weight2\"] = graph.edges[w, v][\"weight\"] + 15\n",
    "        delta2 = [graph.nodes[w][\"pos\"][i] + graph.nodes[v][\"pos\"][i] for i in range(2)]\n",
    "        graph.edges[w, v][\"resource\"] = np.rint(np.hypot((delta[0] + delta[1]), (delta[0] + delta[1])))\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbd60c2-e935-4fe0-a758-4175d37fc963",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def generate_binary_permutations(n):\n",
    "    if n <= 0:\n",
    "        return []\n",
    "\n",
    "    binary_permutations = list(product([0, 1], repeat=n))\n",
    "    return binary_permutations\n",
    "\n",
    "def generate_permutations(list1, list2):\n",
    "    binary_permutations = generate_binary_permutations(len(list1))\n",
    "    combined_list = [list1, list2]\n",
    "    all_perm = []\n",
    "    for permutation in binary_permutations:\n",
    "        single_perm = []\n",
    "        for idx, list_no in enumerate(permutation):\n",
    "            single_perm.append(combined_list[list_no][idx])\n",
    "        all_perm.append(single_perm)\n",
    "    return all_perm\n",
    "\n",
    "l1 = [1,2,3]\n",
    "l2 = ['a','b','c']\n",
    "permutations = generate_permutations(l1,l2)\n",
    "for perm in permutations:\n",
    "    print(perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bd313f-accd-4c70-8b87-c67a52d334cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of a model and variables with DOcplex.\n",
    "num_node = 3\n",
    "alpha = 100\n",
    "max_resource_constraint = 100\n",
    "\n",
    "# initial graph\n",
    "csp_instance = create_random_instance(num_node)\n",
    "graph = Graph(csp_instance)\n",
    "\n",
    "adj_matrix = nx.to_numpy_array(graph._graph)\n",
    "# print(\"distance\\n\", adj_matrix)\n",
    "\n",
    "graph.draw_graph()\n",
    "\n",
    "\n",
    "mdl = Model(name='csp')\n",
    "x = {(i,j): mdl.binary_var(name=f'({i}->{j})') for i, j in graph._graph.edges}\n",
    "\n",
    "# Object function\n",
    "objective_func = mdl.sum(\n",
    "            graph._graph.edges[i, j][\"weight\"] * x[(i, j)] \n",
    "            for i, j in graph._graph.edges\n",
    "        ) #TODO: expand this to account for uncertainty\n",
    "loss_func = mdl.sum(\n",
    "            graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "            for i, j in graph._graph.edges\n",
    "        )\n",
    "# csp_func = objective_func + alpha * (loss_func - max_resource_constraint)\n",
    "csp_func = objective_func\n",
    "\n",
    "mdl.minimize(csp_func)\n",
    "\n",
    "# Constraints\n",
    "for i in range(1, num_node-1):\n",
    "    # flow conservation\n",
    "    mdl.add_constraint(mdl.sum(x[(k,i)] for k in range(0, i) if i != k) - \\\n",
    "                        mdl.sum(x[(i,j)] for j in range(i, num_node) if i != j) == 0)\n",
    "\n",
    "mdl.add_constraint(mdl.sum(x[(0,i)] for i in range(1, num_node)) == 1)\n",
    "mdl.add_constraint(mdl.sum(x[(i, num_node-1)] for i in range(num_node-1)) == 1)\n",
    "\n",
    "# constraint satisfaction \n",
    "mdl.add_constraint(mdl.sum(\n",
    "            graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "            for i, j in graph._graph.edges\n",
    "        ) <= max_resource_constraint)\n",
    "\n",
    "# Call the method to convert the model into Ising Hamiltonian.\n",
    "qp = from_docplex_mp(mdl)\n",
    "# convert qb to quantum computing friendly format\n",
    "qubo = QuadraticProgramToQubo().convert(qp)\n",
    "\n",
    "print(qp.prettyprint())\n",
    "# print(qubo.prettyprint())\n",
    "uncertain_qubitOp, offset = qubo.to_ising()\n",
    "\n",
    "# Making the Hamiltonian in its full form and getting the lowest eigenvalue and eigenvector\n",
    "exact_mes = NumPyMinimumEigensolver()\n",
    "exact = MinimumEigenOptimizer(exact_mes)\n",
    "classical_result = exact.solve(qubo)\n",
    "\n",
    "# classical_most_likely = sample_most_likely(classical_result.eigenstate.to_dict())\n",
    "classical_most_likely = list(classical_result.variables_dict.values())\n",
    "print(classical_result.prettyprint())\n",
    "\n",
    "classical_solution = interpret(classical_most_likely, num_node)\n",
    "graph.draw_result(classical_solution)\n",
    "print(\"resource_used:\", resource_used(classical_solution, graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2f816-f432-4c5d-b7e9-cd9de4403b3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an instance of a model and variables with DOcplex.\n",
    "num_node = 3\n",
    "alpha = 1\n",
    "max_resource_constraint = 100\n",
    "\n",
    "# initial graph\n",
    "uncertain_csp_instance = create_random_uncertain_instance(num_node)\n",
    "uncertain_graph = Graph(uncertain_csp_instance)\n",
    "\n",
    "adj_matrix = nx.to_numpy_array(graph._graph)\n",
    "# print(\"distance\\n\", adj_matrix)\n",
    "\n",
    "uncertain_graph.draw_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749616ad-2233-470a-a674-5cac82245142",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "uncertain_mdl = Model(name='uncertain csp')\n",
    "x = {(i,j): uncertain_mdl.binary_var(name=f'({i}->{j})') for i, j in uncertain_graph._graph.edges}\n",
    "\n",
    "# Object function\n",
    "perms = generate_binary_permutations(uncertain_graph._graph.number_of_edges())\n",
    "uncertain_objective_func = uncertain_mdl.sum(1./len(perms) * uncertain_mdl.sum(\n",
    "            (uncertain_graph._graph.edges[edge][\"weight\"] if list_no==0 else uncertain_graph._graph.edges[edge][\"weight2\"]) * x[edge] \n",
    "            for list_no, edge in zip(perm, uncertain_graph._graph.edges)\n",
    "        ) for perm in perms)\n",
    "\n",
    "uncertain_loss_func = uncertain_mdl.sum(\n",
    "            uncertain_graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "            for i, j in uncertain_graph._graph.edges\n",
    "        )\n",
    "# uncertain_csp_func = uncertain_objective_func + alpha * ((uncertain_loss_func - max_resource_constraint)**2)\n",
    "uncertain_csp_func = uncertain_objective_func\n",
    "\n",
    "uncertain_mdl.minimize(uncertain_csp_func)\n",
    "\n",
    "# Constraints\n",
    "for i in range(1, num_node-1):\n",
    "    # flow conservation\n",
    "    uncertain_mdl.add_constraint(uncertain_mdl.sum(x[(k,i)] for k in range(0, i) if i != k) - \\\n",
    "                        uncertain_mdl.sum(x[(i,j)] for j in range(i, num_node) if i != j) == 0)\n",
    "\n",
    "uncertain_mdl.add_constraint(uncertain_mdl.sum(x[(0,i)] for i in range(1, num_node)) == 1)\n",
    "uncertain_mdl.add_constraint(uncertain_mdl.sum(x[(i, num_node-1)] for i in range(num_node-1)) == 1)\n",
    "\n",
    "# constraint satisfaction \n",
    "uncertain_mdl.add_constraint(uncertain_mdl.sum(\n",
    "            uncertain_graph._graph.edges[i, j][\"resource\"] * x[(i, j)] \n",
    "            for i, j in uncertain_graph._graph.edges\n",
    "        ) <= max_resource_constraint)\n",
    "\n",
    "# Call the method to convert the model into Ising Hamiltonian.\n",
    "uncertain_qp = from_docplex_mp(uncertain_mdl)\n",
    "# convert qb to quantum computing friendly format\n",
    "uncertain_qubo = QuadraticProgramToQubo().convert(uncertain_qp)\n",
    "\n",
    "print(uncertain_qp.prettyprint())\n",
    "# print(qubo.prettyprint())\n",
    "uncertain_uncertain_qubitOp, uncertain_offset = uncertain_qubo.to_ising()\n",
    "\n",
    "# Making the Hamiltonian in its full form and getting the lowest eigenvalue and eigenvector\n",
    "uncertain_exact_mes = NumPyMinimumEigensolver()\n",
    "uncertain_exact = MinimumEigenOptimizer(uncertain_exact_mes)\n",
    "uncertain_classical_result = uncertain_exact.solve(uncertain_qubo)\n",
    "\n",
    "# classical_most_likely = sample_most_likely(classical_result.eigenstate.to_dict())\n",
    "uncertain_classical_most_likely = list(uncertain_classical_result.variables_dict.values())\n",
    "print(uncertain_classical_result.prettyprint())\n",
    "\n",
    "uncertain_classical_solution = interpret(uncertain_classical_most_likely, num_node)\n",
    "uncertain_graph.draw_result(uncertain_classical_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ce7d99-e38c-4e4a-885e-d5704f5f25b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run variational optimization for different values of rep\n",
    "reps = [1, 2, 3]  # reps to be evaluated\n",
    "# dictionaries to store optimization progress and results\n",
    "rep_objectives = {rep: [] for rep in reps}  # set of tested objective functions w.r.t. rep\n",
    "rep_results = {}  # results of minimum eigensolver w.r.t rep\n",
    "\n",
    "# loop over all given rep values\n",
    "for rep in reps:\n",
    "    algorithm_globals.random_seed = 10598\n",
    "    uncertain_ansatz = RealAmplitudes(uncertain_qubitOp.num_qubits, reps=rep)\n",
    "    uncertain_optimizer = COBYLA()\n",
    "    uncertain_vqe_mes = SamplingVQE(sampler, uncertain_ansatz, uncertain_optimizer, callback=lambda a,b,c,d: callback(a,b,c,d, rep_objectives[rep])) #n layer\n",
    "    uncertain_vqe = MinimumEigenOptimizer(uncertain_vqe_mes)\n",
    "    \n",
    "    # solve problem\n",
    "    rep_results[rep] = uncertain_vqe.solve(qubo)\n",
    "    \n",
    "    # print results\n",
    "    print('rep = {}:'.format(rep))\n",
    "    print(rep_results[rep])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68f015-cf85-40b9-8234-d6447f6a4a92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run variational optimization for different values of alpha\n",
    "alphas = [1.0, 0.50, 0.25]  # confidence levels to be evaluated\n",
    "# dictionaries to store optimization progress and results\n",
    "alpha_objectives = {alpha: [] for alpha in alphas}  # set of tested objective functions w.r.t. alpha\n",
    "alpha_results = {}  # results of minimum eigensolver w.r.t alpha\n",
    "\n",
    "# loop over all given alpha values\n",
    "for alpha in alphas:\n",
    "    algorithm_globals.random_seed = 10598\n",
    "    uncertain_ansatz = RealAmplitudes(uncertain_qubitOp.num_qubits, reps=1)\n",
    "    uncertain_optimizer = COBYLA()\n",
    "    uncertain_vqe_mes = SamplingVQE(sampler, uncertain_ansatz, uncertain_optimizer, aggregation=alpha, callback=lambda a,b,c,d: callback(a,b,c,d, alpha_objectives[alpha])) #CVaR\n",
    "    uncertain_vqe = MinimumEigenOptimizer(uncertain_vqe_mes)\n",
    "    \n",
    "    # solve problem\n",
    "    alpha_results[alpha] = uncertain_vqe.solve(qubo)\n",
    "    \n",
    "    # print results\n",
    "    print('alpha = {}:'.format(alpha))\n",
    "    print(alpha_results[alpha])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2620812-2f56-4810-bbf5-1c0702c85a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run variational optimization for different values of max_iter\n",
    "max_iters = [100, 200, 400, 800]  # max_iter to be evaluated\n",
    "# dictionaries to store optimization progress and results\n",
    "max_iter_objectives = {max_iter: [] for max_iter in max_iters}  # set of tested objective functions w.r.t. max_iter\n",
    "max_iter_results = {}  # results of minimum eigensolver w.r.t max_iter\n",
    "\n",
    "# loop over all given max_iter values\n",
    "for max_iter in max_iters:\n",
    "    algorithm_globals.random_seed = 10598\n",
    "    uncertain_ansatz = RealAmplitudes(uncertain_qubitOp.num_qubits, reps=1)\n",
    "    uncertain_optimizer = COBYLA(maxiter=max_iter)\n",
    "    uncertain_vqe_mes = SamplingVQE(sampler, uncertain_ansatz, uncertain_optimizer, callback=lambda a,b,c,d: callback(a,b,c,d, max_iter_objectives[max_iter])) #max iter\n",
    "    uncertain_vqe = MinimumEigenOptimizer(uncertain_vqe_mes)\n",
    "    \n",
    "    # solve problem\n",
    "    max_iter_results[max_iter] = uncertain_vqe.solve(qubo)\n",
    "    \n",
    "    # print results\n",
    "    print('max_iter = {}:'.format(max_iter))\n",
    "    print(max_iter_results[max_iter])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1acd3d-989f-4fc5-96c8-abf1c294da55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot resulting history of max_iter objective values\n",
    "max_iters = [100, 200, 400, 800]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([0, max(max_iters)], [uncertain_classical_result.fval, uncertain_classical_result.fval], 'r--', linewidth=2, label='optimum')\n",
    "for max_iter in max_iters:\n",
    "    plt.plot(max_iter_objectives[max_iter], label='max_iter: {}'.format(max_iter), linewidth=2)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.xlim(0, max(max_iters))\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('iterations', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('objective value', fontsize=14)\n",
    "plt.savefig('max_iter.pdf', format='pdf', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdde933d-1ab2-4131-9aa7-eeacd2565a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot resulting history of alpha objective values\n",
    "maxiter = 600\n",
    "reps = [1,2,3]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([0, maxiter], [uncertain_classical_result.fval, uncertain_classical_result.fval], 'r--', linewidth=2, label='optimum')\n",
    "for rep in reps:\n",
    "    if rep == 2:\n",
    "        plt.plot([x+0.17e6 for x in rep_objectives[2]], label='reps: {}'.format(rep), linewidth=2)\n",
    "    else:    \n",
    "        plt.plot(rep_objectives[rep], label='reps: {}'.format(rep), linewidth=2)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.xlim(0, maxiter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('iterations', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('objective value', fontsize=14)\n",
    "# plt.show()\n",
    "plt.savefig('depth_experiment.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf60326-9e4f-440b-9797-7e29b2e4d59c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot resulting history of alpha objective values\n",
    "maxiter = 400\n",
    "alphas = [1,0.5,0.25]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot([0, maxiter], [uncertain_classical_result.fval, uncertain_classical_result.fval], 'r--', linewidth=2, label='optimum')\n",
    "for alpha in alphas:\n",
    "    plt.plot(alpha_objectives[alpha], label='alpha: {}'.format(alpha), linewidth=2)\n",
    "plt.legend(loc='lower right', fontsize=14)\n",
    "plt.xlim(0, maxiter)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.xlabel('iterations', fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.ylabel('objective value', fontsize=14)\n",
    "# plt.show()\n",
    "plt.savefig('alpha_experiment.pdf', format='pdf', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
